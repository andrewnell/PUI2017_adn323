{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Time series clustering exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile \n",
    "import geopandas as gpd\n",
    "import pylab as pl\n",
    "from scipy.cluster.vq import kmeans2,kmeans, whiten\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "import sklearn.cluster\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "% pylab inline\n",
    "import scipy.cluster as scp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the census bureau business data for all years 1993-2014. You can investigate using the API (I have not done it with the census bureau). I did is as you see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-12-19 10:34:50--  ftp://ftp.census.gov/Econ2001_And_Earlier/CBP_CSV/zbp93totals.zip\n",
      "           => “zbp93totals.zip”\n",
      "Resolving ftp.census.gov... 148.129.75.35, 2610:20:2010:a09:1000:0:9481:4b23\n",
      "Connecting to ftp.census.gov|148.129.75.35|:21... connected.\n",
      "Logging in as anonymous ... \n",
      "Error in server response, closing control connection.\n",
      "Retrying.\n",
      "\n",
      "--2017-12-19 10:39:51--  ftp://ftp.census.gov/Econ2001_And_Earlier/CBP_CSV/zbp93totals.zip\n",
      "  (try: 2) => “zbp93totals.zip”\n",
      "Connecting to ftp.census.gov|148.129.75.35|:21... connected.\n",
      "Logging in as anonymous ... "
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Download all datasets\n",
    "#these commands can be run on the shell and get the data with the command wget\n",
    "#the cell needs to be run only once\n",
    "!for ((y=93; y<=99; y+=1)); do wget \\\n",
    "ftp://ftp.census.gov/Econ2001_And_Earlier/CBP_CSV/zbp$y\\totals.zip; done\n",
    "\n",
    "!for ((y=0; y<=1; y+=1)); do wget \\\n",
    "ftp://ftp.census.gov/Econ2001_And_Earlier/CBP_CSV/zbp0$y\\totals.zip; done\n",
    "\n",
    "!for ((y=2; y<=9; y+=1)); do wget \\\n",
    "ftp://ftp.census.gov/econ200$y\\/CBP_CSV/zbp0$y\\totals.zip; done\n",
    "\n",
    "!for ((y=10; y<=14; y+=1)); do wget \\\n",
    "ftp://ftp.census.gov/econ20$y\\/CBP_CSV/zbp$y\\totals.zip; done\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Move data to folder in PUIDATA\n",
    "os.system('mkdir ' + os.getenv('PUIDATA') + '/NYC_ZIPBusinessData')\n",
    "for y in range(93,100,1):\n",
    "    os.system('mv zbp' + str(y) + 'totals.zip ' + os.getenv('PUIDATA') + '/NYC_ZIPBusinessData')\n",
    "\n",
    "for y in range(0,10,1):\n",
    "    os.system('mv zbp0' + str(y) + 'totals.zip ' + os.getenv('PUIDATA') + '/NYC_ZIPBusinessData')\n",
    "    \n",
    "for y in range(10,15,1):\n",
    "    os.system('mv zbp' + str(y) + 'totals.zip ' + os.getenv('PUIDATA') + '/NYC_ZIPBusinessData')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-07T07:06:43.156591",
     "start_time": "2017-12-07T07:06:41.245257"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    " Download the NYC zipcodes shapefile. One of many ways in which you can get the zipcodes shapefile for NYC\n",
    " https://data.cityofnewyork.us/download/i8iw-xf4u/application%2Fzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Download and unzip Zipcode shapefiles into PUIdata\n",
    "!wget https://data.cityofnewyork.us/download/i8iw-xf4u/application%2Fzip -O NYCZipcodeShapes.zip\n",
    "os.system('mkdir ' + os.getenv('PUIDATA') + '/NYC_Zipcode_Shapefile')\n",
    "os.system(\"unzip \" + 'NYCZipcodeShapes.zip' + \" -d \" + os.getenv('PUIDATA') + '/NYC_Zipcode_Shapefile')\n",
    "os.system('mv NYCZipcodeShapes.zip ' + os.getenv('PUIDATA') + '/NYC_Zipcode_Shapefile' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "ZipShape = gpd.read_file(os.getenv('PUIDATA') +\\\n",
    "                         '/NYC_Zipcode_Shapefile/ZIP_CODE_040114.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Only take relevant info from Zip shape file\n",
    "ZipShapedf = ZipShape[['ZIPCODE','geometry']]\n",
    "\n",
    "# Format columns into desired format for merging later on\n",
    "ZipShapedf['ZIPCODE'] = pd.to_numeric(ZipShapedf['ZIPCODE'], errors='coerce')\n",
    "ZipShapedf.rename(columns={'ZIPCODE':'zip'},inplace=True)\n",
    "\n",
    "# Review data\n",
    "ZipShapedf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## You can use zipfile module in python to unzip the files\n",
    "it should be install in your system, but if it is not you can get the code with wget from here\n",
    "https://github.com/python/cpython/blob/2.7/Lib/zipfile.py\n",
    "remembering to use the raw link\n",
    "(or you can use the usual shell commands, and miss the chance to learn something new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "Businessdf = pd.DataFrame(columns={'zip','name','empflag','emp','qp1','ap',\n",
    "                                   'est','year'})\n",
    "Businessdf.head()\n",
    "\n",
    "# For 94 to 99\n",
    "for i in range(94,100,1):\n",
    "    # Read in data using zip module\n",
    "    fname = 'zbp' + ('{:02d}'.format(i)) + 'totals.zip'\n",
    "    zf = zipfile.ZipFile(os.getenv('PUIDATA') + '/NYC_ZIPBusinessData' +\\\n",
    "                         '/' + fname)\n",
    "    df = pd.read_csv(zf.open(fname.replace('.zip','.txt')))\n",
    "    \n",
    "    # The format and naming convetnions of the data changes, so to \n",
    "    # ensure consistency these two lines of code are used\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    df = df[['zip','name','empflag','emp','qp1','ap','est']]\n",
    "    \n",
    "    # Create column for year\n",
    "    df['year'] = str(19) + ('{:02d}'.format(i))\n",
    "    \n",
    "    # Merge onto big dataframe\n",
    "    Businessdf = pd.concat([Businessdf,df])\n",
    "\n",
    "# For 2000 to 2014\n",
    "for i in range(0,15,1):\n",
    "    # Read in data using zip module\n",
    "    fname = 'zbp' + ('{:02d}'.format(i)) + 'totals.zip'\n",
    "    zf = zipfile.ZipFile(os.getenv('PUIDATA') + '/NYC_ZIPBusinessData' +\\\n",
    "                         '/' + fname)\n",
    "    df = pd.read_csv(zf.open(fname.replace('.zip','.txt')))\n",
    "    \n",
    "    # The format and naming convetnions of the data changes, \n",
    "    # so to ensure consistence these two lines of code are used\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    df = df[['zip','name','empflag','emp','qp1','ap','est']]\n",
    "    \n",
    "    # Create column for year\n",
    "    df['year'] = str(20) + ('{:02d}'.format(i))\n",
    "    \n",
    "    # Merge onto big dataframe\n",
    "    Businessdf = pd.concat([Businessdf,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Businessdf.zip = Businessdf.zip.astype(int)\n",
    "Businessdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you may need to clean your data: for some NYC zip codes there may be no info\n",
    "sanity check: you should have 20 (N_timestamps) datapoints per time series and about 250 zipcodes (Nzipcodes)\n",
    "\n",
    "\n",
    "IMPORTANT: we talked about the importance of \"whitening\" your data.\n",
    "Whitenings decorrelates the data: it makes the features independent so that the data covariance matrix is the identity matrix.\n",
    "Whitening your data in time series analysis is in most cases **wrong**: you are modifying your time behaviour. This is because of the strong correlation between features (two consecutive time stamps for the same observation, the same zip code here, are strongly correlated). Here instead you want to standardize your time series: subtract the mean and divide each time series (separately) by its standard deviation. As a sanity check (if you use skitlearn Kmeans or skitlearns kmeans2): you want your data array to be shaped Nzipcodes x Ntimestamps\n",
    "\n",
    "mydata.shape should be (Nzipcodes, Ntimestamps)\n",
    "\n",
    "mydata[i].std() shoould be 1 for all i in range(len(Nzipcodes))\n",
    "\n",
    "mydata[i].mean() should be ~0 for all i in range(len(Nzipcodes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASKS:\n",
    "    \n",
    "    1. get and prep your data.\n",
    "    2. cluster the NUMBER OF ESTABLISHMENTS time series with K-means in **a few** clusters (as discussed there is no real good, sound way to decide what a good number is here. try a few options, keeping in mind a few is more than a couple, but i recommand you stay within the single digit numbers)\n",
    "    3. plot the cluster centers (if you used K means those are the means of the clusters). you can plot for example the cluster centers overlayed on each time series (using the alpha channel to control the opacity in the plot may be helpful here).\n",
    "    4. Use another clustering algorithm (of your choice)\n",
    "    5. overlay your data on a NYC map: you can use shapefiles for the zip codes and different colors for different clusters\n",
    "    6. Compare the results of the 2 algorithms\n",
    "    7. attempt an interpretation. this is dangerous ground: clustering is an exploratory tool so you do not want to jump to conclusions because you see some clusters! but seeing structure in your data can inform your next moves as an investigator. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get and Prep the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df with Zip Shape file to ensure only NYC zips are included\n",
    "Businessdf_ = pd.merge(Businessdf,ZipShapedf,on='zip').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see differences in data sets between years\n",
    "print('year','Number of Rows','Unique Zips')\n",
    "for i in range(1994,2015,1):\n",
    "    print(i,len(Businessdf_.zip[Businessdf_.year == str(i)]),\n",
    "          len(Businessdf_.zip[Businessdf_.year == str(i)].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there are multiple years with null data sets for differing zips, however, once we remove duplicates these disappear. It appears to be an issue with the polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Drop duplicate data sets - seem to be identical except for geometry\n",
    "Businessdf_.drop_duplicates(['zip','year'],inplace=True)\n",
    "\n",
    "# Pivot table to pivot zips against years\n",
    "Businessdf = Businessdf_.pivot(columns='zip', index='year', values='est')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Businessdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a normal dataframe to normalise\n",
    "NormBusinessdf = Businessdf.copy()\n",
    "\n",
    "# Create loop that normalises row by row\n",
    "for i in list(NormBusinessdf.columns):\n",
    "    rowmean = NormBusinessdf[i].mean()\n",
    "    rowstd = NormBusinessdf[i].std()\n",
    "    NormBusinessdf[i] = (NormBusinessdf[i] - rowmean) / rowstd\n",
    "    \n",
    "# Review data \n",
    "NormBusinessdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Null Values\n",
    "sum(NormBusinessdf.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormBusinessdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all values that are Null\n",
    "NormBusinessdf.dropna(axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormBusinessdf.shape\n",
    "# We lose 15 Rows of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster the number of Establishments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First plot the time series for each zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure\n",
    "pl.figure(figsize=(12,6))\n",
    "\n",
    "# Plot Figure\n",
    "pl.plot(NormBusinessdf,alpha=0.1,c='k');\n",
    "\n",
    "# Format Plot\n",
    "pl.title('Time series of Number of \\nestablishments per Zipcode',\n",
    "         fontsize=20)\n",
    "pl.xlabel('year', fontsize=15)\n",
    "pl.ylabel('Normalised Number of Establishments',fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 1: Time series of Normalised Number of Establishments per year from 1994 to 2014\n",
    "It is important to note that there is a clear trend that most of the zipcodes follow, which is indicated by the darker middle section, however there are multiple zipcodes that do not follow the same trend as can be seen by all the 'noisy' offshoot lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Elbow test to determine correct number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Function courtesy of Prof Sobolevsky\n",
    "def elbow(data,K):\n",
    "#data is your input as numpy form\n",
    "#K is a list of number of clusters you would like to show.\n",
    "    # Run the KMeans model and save all the results for each number of clusters\n",
    "    KM = [KMeans(n_clusters=k).fit(data) for k in K]\n",
    "    \n",
    "    # Save the centroids for each model with a increasing k\n",
    "    centroids = [k.cluster_centers_ for k in KM]\n",
    "\n",
    "    # For each k, get the distance between the data with each center. \n",
    "    D_k = [cdist(data, cent, 'euclidean') for cent in centroids]\n",
    "    \n",
    "    # But we only need the distance to the nearest centroid since \n",
    "    # we only calculate dist(x,ci) for its own cluster.\n",
    "    globals()['dist'] = [np.min(D,axis=1) for D in D_k]\n",
    "    \n",
    "    # Calculate the Average SSE.\n",
    "    avgWithinSS = [sum(d)/data.shape[0] for d in dist]\n",
    "    \n",
    "    \n",
    "    # elbow curve\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(K, avgWithinSS, 'b*-')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Average within-cluster sum of squares')\n",
    "    plt.title('Elbow for KMeans clustering')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # Total with-in sum of square plot. Another way to show the result.\n",
    "    wcss = [sum(d**2) for d in dist]\n",
    "    tss = sum(pdist(data)**2)/data.shape[0]\n",
    "    bss = tss-wcss\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(K, bss/tss*100, 'b*-')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Percentage of variance explained')\n",
    "    plt.title('Elbow for KMeans clustering')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbow(NormBusinessdf.T, range(1,30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 2: Elbow Test output of different Cluster sizes\n",
    "Note how there is no clear elbow, however the best fit appears to be between 4 and 6, where the increase in cluster size starts to provide less percentage explanation in variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Kmeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty arrays\n",
    "clusters = []\n",
    "centers = []\n",
    "\n",
    "# Run 3 types of clusters\n",
    "for n in range(4,7,1):\n",
    "    km = KMeans(random_state=300, n_clusters=n)\n",
    "    res = km.fit(NormBusinessdf.T)\n",
    "    clusters.append(res.labels_)\n",
    "    centers.append(res.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transposed dataframe\n",
    "NormBusinessdfT = NormBusinessdf.T.copy()\n",
    "\n",
    "# Add clusters onto Dataframe\n",
    "NormBusinessdfT['4 Clusters'] = clusters[0]\n",
    "NormBusinessdfT['5 Clusters'] = clusters[1]\n",
    "NormBusinessdfT['6 Clusters'] = clusters[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Define Colour Scheme\n",
    "colours = ['r','g','b','orange','purple','k']\n",
    "\n",
    "for i in range(4,7,1):\n",
    "    # Set up plots\n",
    "    fig, ax = pl.subplots(figsize=(12,6))\n",
    "    for p in range(0,i,1):\n",
    "        # Plot Time Series with colours and centroids\n",
    "        pl.plot(NormBusinessdfT[NormBusinessdfT[str(i) + \\\n",
    "                                                ' Clusters']==p].T[:-3],\n",
    "                c=colours[p],alpha=0.075)\n",
    "        pl.plot(list(NormBusinessdfT.columns)[:-3],centers[i-4][p],\n",
    "                c=colours[p])\n",
    "        \n",
    "        # Format Plots\n",
    "        pl.title(str(i) + ' Clusters - KMeans',fontsize=15)\n",
    "        pl.xlabel('year', fontsize=15)\n",
    "        pl.ylabel('Normalised Number of Establishments',fontsize=15)\n",
    "        pl.ylim(-3,4)\n",
    "        \n",
    "        # For Animation to display\n",
    "        time.sleep(0.01) # too slow it down\n",
    "        clear_output(wait=True)\n",
    "        display(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 3: The Clustered time series data plotted with 3 different clusters (4,5,6)\n",
    "Note how the solid line indicating the kmean value per year moves through the center of the lighter lines as expected. It is important to note that although in each case there is one clearly defined cluster, the others tend to have more variability as the noisier time series tend to to not follow as much of a pattern. \n",
    "\n",
    "\n",
    "Visually it looks like the 5 clusters may be the best in this case, as the lines seem to follow a specific trend with little deviation, whereas it becomes messy at 6 clusters and appears too coarse at 4 clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other means of clustering - Using Dendograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "fig = pl.figure(figsize=(20,60))\n",
    "\n",
    "ddg = scp.hierarchy.dendrogram(scp.hierarchy.linkage(NormBusinessdf.T, \n",
    "                                                     method='ward'),\n",
    "                               labels = list(NormBusinessdf.columns),\n",
    "                               leaf_rotation=270.,leaf_font_size=20, \n",
    "                               truncate_mode='lastp', p=250, \n",
    "                               show_contracted=True, color_threshold = 14, \n",
    "                               orientation='left', above_threshold_color='k'\n",
    "                              )  # font size for the x axis labels)\n",
    "#pl.xticks(rotation=90)\n",
    "pl.xlabel(\"Distance\", fontsize=20)\n",
    "pl.ylabel(\"ZipCodes\", fontsize=20)\n",
    "pl.yticks(fontsize=15, rotation=0)\n",
    "pl.xticks(fontsize=15)\n",
    "pl.grid('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 4: Heirarchical Clustering Displayed in a Dendogram for time series of number of establishments by different zipcodes \n",
    "Note how we have set the threshold to 14 and we have 5 distinct clusters in this scenario. However, this threshold can be adjusted to show different grouoings and different levels.\n",
    "\n",
    "This also follows the Kmeans clustering idication that there is a big cluster that most zipcodes follow (sjown as the teal group in the above figure)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Clustering Methods -  Agglomerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty arrays\n",
    "clustersagc = []\n",
    "\n",
    "# Run 3 types of clusters\n",
    "for n in range(4,7,1):\n",
    "    agc = AgglomerativeClustering(n_clusters=n,  \n",
    "                                  compute_full_tree=True).fit(NormBusinessdf.T)\n",
    "    clustersagc.append(agc.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add clusters onto Dataframe\n",
    "NormBusinessdfT['4 Clusters AGC'] = clustersagc[0]\n",
    "NormBusinessdfT['5 Clusters AGC'] = clustersagc[1]\n",
    "NormBusinessdfT['6 Clusters AGC'] = clustersagc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Define Colour Scheme\n",
    "colours = ['r','g','b','orange','purple','k']\n",
    "\n",
    "\n",
    "for i in range(4,7,1):\n",
    "    # Set up plots\n",
    "    fig, ax = pl.subplots(figsize=(12,6))\n",
    "    for p in range(0,i,1):\n",
    "        # Plot Time Series with colours and centroids\n",
    "        pl.plot(NormBusinessdfT[NormBusinessdfT[str(i) + \\\n",
    "                                                ' Clusters AGC']==p].T[:-6],\n",
    "                c=colours[p],alpha=0.075)\n",
    "        pl.plot(list(NormBusinessdfT.columns)[:-6],\n",
    "                NormBusinessdfT[NormBusinessdfT[str(i) + ' Clusters AGC'\\\n",
    "                                               ] ==p].mean()[:-6],c=colours[p])\n",
    "        \n",
    "        # Format Plots\n",
    "        pl.title(str(i) + ' Clusters - Agglomerative - Ward Linkage',\n",
    "                 fontsize=15)\n",
    "        pl.xlabel('year', fontsize=15)\n",
    "        pl.ylabel('Normalised Number of Establishments',fontsize=15)\n",
    "        pl.ylim(-3,4)\n",
    "        \n",
    "        # For Animation to display\n",
    "        time.sleep(0.01) # too slow it down\n",
    "        clear_output(wait=True)\n",
    "        display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 5: Agglomeratuve - Ward Linkage Clustering with 4, 5 and 6 clusters\n",
    "\n",
    "Note how the clusters appear very similar to the Kmeans method, although slightly different in some cases. There are similar things to note with the one strong cluster and the other clusters with more noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviww clusters to compare differences\n",
    "NormBusinessdfT[['4 Clusters','4 Clusters AGC',\n",
    "                 '5 Clusters', '5 Clusters AGC', \n",
    "                 '6 Clusters','6 Clusters AGC']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters are mostly identical with different numbering schemes, however there are some differences between the two tyes of clustering methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now to plot the data on maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to merge the shapefile onto the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data with polygons and turn into Geopandas data frame\n",
    "Mapdf = pd.merge(NormBusinessdfT.reset_index(),ZipShapedf,on='zip')\n",
    "Mapdf = gpd.GeoDataFrame(Mapdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Functions to inout discrete colour bars\n",
    "# Found at http://sensitivecities.com/so-youd-like-to-make-a-\n",
    "# map-using-python-EN.html#.WjKrVN-nFPY\n",
    "def colorbar_index(ncolors, cmap, labels=None, **kwargs):\n",
    "    \"\"\"\n",
    "    This is a convenience function to stop you making off-by-one errors\n",
    "    Takes a standard colour ramp, and discretizes it,\n",
    "    then draws a colour bar with correctly aligned labels\n",
    "    \"\"\"\n",
    "    cmap = cmap_discretize(cmap, ncolors)\n",
    "    mappable = cm.ScalarMappable(cmap=cmap)\n",
    "    mappable.set_array([])\n",
    "    mappable.set_clim(-0.5, ncolors+0.5)\n",
    "    colorbar = plt.colorbar(mappable, **kwargs)\n",
    "    colorbar.set_ticks(np.linspace(0, ncolors, ncolors))\n",
    "    colorbar.set_ticklabels(range(ncolors))\n",
    "    if labels:\n",
    "        colorbar.set_ticklabels(labels)\n",
    "    return colorbar\n",
    "\n",
    "def cmap_discretize(cmap, N):\n",
    "    \"\"\"\n",
    "    Return a discrete colormap from the continuous colormap cmap.\n",
    "\n",
    "        cmap: colormap instance, eg. cm.jet. \n",
    "        N: number of colors.\n",
    "\n",
    "    Example\n",
    "        x = resize(arange(100), (5,100))\n",
    "        djet = cmap_discretize(cm.jet, 5)\n",
    "        imshow(x, cmap=djet)\n",
    "\n",
    "    \"\"\"\n",
    "    if type(cmap) == str:\n",
    "        cmap = get_cmap(cmap)\n",
    "    colors_i = np.concatenate((np.linspace(0, 1., N), (0., 0., 0., 0.)))\n",
    "    colors_rgba = cmap(colors_i)\n",
    "    indices = np.linspace(0, 1., N + 1)\n",
    "    cdict = {}\n",
    "    for ki, key in enumerate(('red', 'green', 'blue')):\n",
    "        cdict[key] = [(indices[i], colors_rgba[i - 1, ki], \n",
    "                       colors_rgba[i, ki]) for i in xrange(N + 1)]\n",
    "    return matplotlib.colors.LinearSegmentedColormap(cmap.name + \"_%d\" % N, \n",
    "                                                     cdict, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot for each of the 3 clusters selected for Kmeans\n",
    "for i in range(4,7,1):\n",
    "\n",
    "    # Set up figures\n",
    "    fig,ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "    # Plot Data\n",
    "    Mapdf.plot(column = str(i) + ' Clusters',ax=ax, \n",
    "               edgecolor='black', lw=0.5, alpha=1, \n",
    "               cmap='Blues_r',legend=False)\n",
    "\n",
    "    # Format Plot\n",
    "    ax.set_title(str(i) + ' Clusters - KMeans',fontsize=15)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.axis('off');\n",
    "    \n",
    "    # Add a colour bar\n",
    "    cb = colorbar_index(ncolors=i, cmap='Blues', labels=list(np.arange(1,i+1,1)))\n",
    "    cb.ax.tick_params(labelsize=15)\n",
    "    \n",
    "    # For Animation to display\n",
    "    time.sleep(1) # too slow it down\n",
    "    clear_output(wait=True)\n",
    "    display(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 6: Maps showing kmean clustering of the zipcodes by number of establishments per Zipcode\n",
    "For the most part, most zipcodes behave the same, however we see the biggest difference in areas in Midetown and Downtown Manhattan, which makes sense as this areas has changed substantially over the time period, and is also home to many businesses. There are a couple other areas on the outskirts of the city that also fall into different clusters. This could be attributed to the fact that it is cheaper to get property on the outskirts and could have something to do with more industrial businesses setting up shop at different time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot for each of the 3 clusters selected for Agglomorative\n",
    "for i in range(4,7,1):\n",
    "\n",
    "    # Set up figures\n",
    "    fig,ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "    # Plot Data\n",
    "    Mapdf.plot(column = str(i) + ' Clusters AGC',ax=ax, \n",
    "               edgecolor='black', lw=0.5, alpha=1, \n",
    "               cmap='Blues_r',legend=False)\n",
    "\n",
    "    # Format Plot\n",
    "    ax.set_title(str(i) + ' Clusters - Agglomeative - Ward Linkage ',\n",
    "                 fontsize=15)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.axis('off');\n",
    "    \n",
    "    # Add a colour bar\n",
    "    cb = colorbar_index(ncolors=i, cmap='Blues', labels=list(np.arange(1,i+1,1)))\n",
    "    cb.ax.tick_params(labelsize=15)\n",
    "    \n",
    "    # For Animation to display\n",
    "    time.sleep(1) # too slow it down\n",
    "    clear_output(wait=True)\n",
    "    display(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 7: Maps showing agglomerative clustering of the zipcodes by number of establishments per Zipcode\n",
    "For the most part, most zipcodes behave the same, however we see the biggest difference in areas in Midetown and Downtown Manhattan, which makes sense as this areas has changed substantially over the time period, and is also home to many businesses. There are a couple other areas on the outskirts of the city that also fall into different clusters. This could be attributed to the fact that it is cheaper to get property on the outskirts and could have something to do with more industrial businesses setting up shop at different time periods.\n",
    "\n",
    "These maps are almost identical to the Kmean Clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Moves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both methods of clustering showed similar results, we may want to compare the clustering with several other types of clustering methods to see if there are any major differences. For the most part, the results indicate what we would expect to see and that is Midtown and Downtown behavong dfferently to the rest of New York, most likely due to the number of businesses in these areas and because they are areas that have changed drastically in the last 20 years. It may be interesting to take the analysis slightly further and see if we can see the impacts spreading into downtown Brooklyn or potentially differences in Gentrified areas. However none of this is conclusive. \n",
    "\n",
    "We see similarly that the outskirts of the city behave differently. This could be attributed to the fact that these may be indistrial areas with small businesses set up to feed and support indistry as they have been pushed further from the city center due to densification and rising costs.\n",
    "\n",
    "An important next step would be to understand which clusters are seeing businesses grow in number and which are decreasing, this could potentially be used by the city to identify areas where businesses are struggling to thrive and maybe understand what they can do support these businesses and ensure there is some form of job creation and economic stimulation in some of tehse areas and the city overall. It would be very important to try and investigate if the results can be confirmed with some groundtruth and facts about the areas that are clustered together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASH Score 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "PUI2016_Python2",
   "language": "python",
   "name": "pui2016_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "514px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
